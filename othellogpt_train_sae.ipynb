{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:441: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n",
      "/usr/local/lib/python3.10/dist-packages/transformers/utils/generic.py:309: UserWarning: torch.utils._pytree._register_pytree_node is deprecated. Please use torch.utils._pytree.register_pytree_node instead.\n",
      "  _torch_pytree._register_pytree_node(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: 512-L1-0.0002-LR-3e-05-Tokens-1.000e+06\n",
      "n_tokens_per_buffer (millions): 0.060416\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 244.0\n",
      "Total wandb updates: 8.0\n",
      "n_tokens_per_feature_sampling_window (millions): 120.832\n",
      "n_tokens_per_dead_feature_window (millions): 241664.0\n",
      "Using Ghost Grads.\n",
      "We will reset the sparsity calculation 0.0 times.\n",
      "Number tokens in sparsity calculation window: 2.05e+06\n",
      "Loaded pretrained model othello-gpt into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55955d7fb2374c91b62df4ad7106225e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "023a9f0ec27444c3a1a5f3d0a89f8232",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is tokenized! Updating config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Objective value: 22.3585:  10%|█         | 10/100 [00:03<00:32,  2.74it/s]\n",
      "/workspace/mats_sae_training/sae_training/sparse_autoencoder.py:173: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  out = torch.tensor(out, dtype=self.dtype, device=self.device)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitializing b_dec with geometric median of activations\n",
      "Previous distances: 23.284273147583008\n",
      "New distances: 22.28409194946289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "244| MSE Loss 0.084 | L1 0.057: 100%|█████████▉| 999424/1000000.0 [00:18<00:00, 49082.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to checkpoints/r1e9986g/final_sparse_autoencoder_othello-gpt_blocks.6.hook_resid_pre_512.pt\n",
      "Run name: 8192-L1-0.0002-LR-3e-05-Tokens-1.000e+06\n",
      "n_tokens_per_buffer (millions): 0.060416\n",
      "Lower bound: n_contexts_per_buffer (millions): 0.001024\n",
      "Total training steps: 244.0\n",
      "Total wandb updates: 8.0\n",
      "n_tokens_per_feature_sampling_window (millions): 120.832\n",
      "n_tokens_per_dead_feature_window (millions): 241664.0\n",
      "Using Ghost Grads.\n",
      "We will reset the sparsity calculation 0.0 times.\n",
      "Number tokens in sparsity calculation window: 2.05e+06\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "244| MSE Loss 0.084 | L1 0.057: : 1003520it [00:34, 49082.79it/s]                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model othello-gpt into HookedTransformer\n",
      "Moving model to device:  cuda\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "858926821f0045538b0ed088a1805da4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0add4e50300846c594338802bfb8df2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Resolving data files:   0%|          | 0/20 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset is tokenized! Updating config.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "244| MSE Loss 0.084 | L1 0.057: : 1003520it [01:32, 10871.49it/s]\n",
      "Objective value: 22.3597:  10%|█         | 10/100 [00:03<00:34,  2.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reinitializing b_dec with geometric median of activations\n",
      "Previous distances: 23.286479949951172\n",
      "New distances: 22.28495979309082\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "244| MSE Loss 0.078 | L1 0.226: : 1003520it [00:20, 66651.79it/s]                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved model to checkpoints/vsrt2ynw/final_sparse_autoencoder_othello-gpt_blocks.6.hook_resid_pre_8192.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "244| MSE Loss 0.078 | L1 0.226: : 1003520it [00:38, 66651.79it/s]"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "import sys\n",
    "\n",
    "os.environ[\"TOKENIZERS_PARALLELISM\"] = \"false\"\n",
    "os.environ[\"WANDB__SERVICE_WAIT\"] = \"300\"\n",
    "\n",
    "dataset_path = 'taufeeque/othellogpt'\n",
    "model_name = 'othello-gpt'\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "\n",
    "from sae_training.config import LanguageModelSAERunnerConfig\n",
    "from sae_training.lm_runner import language_model_sae_runner\n",
    "\n",
    "for l1_coefficient in [0.0002, 0.0001]:\n",
    "    for exp_factor in [0.5, 1, 4, 16, 64]:\n",
    "        config = LanguageModelSAERunnerConfig(\n",
    "            model_name=model_name,\n",
    "            hook_point=\"blocks.6.hook_resid_pre\",\n",
    "            hook_point_layer=6,\n",
    "            dataset_path=dataset_path,\n",
    "            context_size=59,\n",
    "            d_in=512,\n",
    "            n_batches_in_buffer=32,\n",
    "            # total_training_tokens=1*(1e6), # prev: 10*(1e6)\n",
    "            total_training_tokens=100*(1e6), # prev: 10*(1e6)\n",
    "            store_batch_size=32,\n",
    "            device=device,\n",
    "            seed=42,\n",
    "            dtype=torch.float32,\n",
    "            b_dec_init_method=\"geometric_median\", # todo: geometric_median\n",
    "            expansion_factor=exp_factor, # todo: adjust\n",
    "            l1_coefficient=l1_coefficient, # prev: 0.001, 0.0001, 0.0002\n",
    "            lr=0.00003, # prev: 0.0003\n",
    "            lr_scheduler_name=\"constantwithwarmup\",\n",
    "            lr_warm_up_steps=5000,\n",
    "            train_batch_size=4096,\n",
    "            use_ghost_grads=True,\n",
    "            feature_sampling_window=500,\n",
    "            dead_feature_window=1e6,\n",
    "            log_to_wandb=True,\n",
    "            wandb_project=\"othello_gpt_sae\",\n",
    "            wandb_log_frequency=30,\n",
    "            n_checkpoints=0,\n",
    "            checkpoint_path=\"checkpoints\",\n",
    "            start_pos_offset=5, # exclude first seq position\n",
    "            end_pos_offset=-5\n",
    "        )\n",
    "\n",
    "        sparse_autoencoder = language_model_sae_runner(config)\n",
    "    # import time\n",
    "    # rand_string = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "python mats_sae_training/sae_simple_train.py --l1_coefficient 0.0002 --exp_factor 0.5\n",
      "python mats_sae_training/sae_simple_train.py --l1_coefficient 0.0002 --exp_factor 1\n",
      "python mats_sae_training/sae_simple_train.py --l1_coefficient 0.0002 --exp_factor 4\n",
      "python mats_sae_training/sae_simple_train.py --l1_coefficient 0.0002 --exp_factor 16\n",
      "python mats_sae_training/sae_simple_train.py --l1_coefficient 0.0002 --exp_factor 64\n",
      "python mats_sae_training/sae_simple_train.py --l1_coefficient 0.0001 --exp_factor 0.5\n",
      "python mats_sae_training/sae_simple_train.py --l1_coefficient 0.0001 --exp_factor 1\n",
      "python mats_sae_training/sae_simple_train.py --l1_coefficient 0.0001 --exp_factor 4\n",
      "python mats_sae_training/sae_simple_train.py --l1_coefficient 0.0001 --exp_factor 16\n",
      "python mats_sae_training/sae_simple_train.py --l1_coefficient 0.0001 --exp_factor 64\n"
     ]
    }
   ],
   "source": [
    "for l1_coefficient in [0.0002, 0.0001]:\n",
    "    for exp_factor in [0.5, 1, 4, 16, 64]:\n",
    "        print(f\"python mats_sae_training/sae_simple_train.py --l1_coefficient {l1_coefficient} --exp_factor {exp_factor}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mats_sae_training",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
